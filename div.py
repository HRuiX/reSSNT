import os
import json
import shutil
import tempfile
import lpips
from typing import List, Dict, Tuple, Optional, Union
from pathlib import Path
from collections import defaultdict
import warnings
from pytorch_fid import fid_score
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.cluster import KMeans
from scipy import stats
from scipy.stats import spearmanr, kendalltau
import torchvision.transforms as transforms
from torchvision.models import inception_v3
from skimage.metrics import structural_similarity as ssim

# Optional imports with fallbacks
try:
    from image_diversity import ClipMetrics, InceptionMetrics
    CLIP_AVAILABLE = True
except ImportError:
    CLIP_AVAILABLE = False
    print("Warning: image_diversity not available. TCE/TIE metrics will be disabled.")

warnings.filterwarnings('ignore')

class ImageDataset(Dataset):
    """ç»Ÿä¸€çš„å›¾åƒæ•°æ®é›†ç±»"""
    def __init__(self, image_paths: List[str], transform=None):
        self.image_paths = image_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        path = self.image_paths[idx]
        try:
            image = Image.open(path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, path
        except Exception as e:
            print(f"Error loading image {path}: {e}")
            if self.transform:
                dummy = Image.new('RGB', (256, 256), (0, 0, 0))
                return self.transform(dummy), path
            return None, path


class ImprovedFIDContributionCalculator:
    """æ”¹è¿›çš„FIDè´¡çŒ®è®¡ç®—å™¨ - åŸºäºæˆ‘ä»¬è®¨è®ºçš„æƒ³æ³•å®ç°"""
    
    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = torch.device(device)
        
        
    
    def _safe_calculate_fid_fixed(self, path1: str, path2: str, batch_size: int) -> float:
        """
        å¿«é€Ÿä¿®å¤ç‰ˆæœ¬çš„FIDè®¡ç®— - è§£å†³å°ºå¯¸ä¸ä¸€è‡´é—®é¢˜
        ç›´æ¥æ›¿æ¢åŸä»£ç ä¸­çš„ _safe_calculate_fid æ–¹æ³•
        """
        # ğŸ”‘ å…³é”®ä¿®å¤ï¼šé¢„å¤„ç†å›¾åƒåˆ°ç»Ÿä¸€å°ºå¯¸
        processed_path1 = self._preprocess_images_to_uniform_size(path1, target_size=(299, 299))
        processed_path2 = self._preprocess_images_to_uniform_size(path2, target_size=(299, 299))
        
        try:
            # ä½¿ç”¨é¢„å¤„ç†åçš„è·¯å¾„è®¡ç®—FID
            fid_score_val = fid_score.calculate_fid_given_paths(
                [processed_path1, processed_path2],
                batch_size=min(batch_size, 16),  # é™åˆ¶batch size
                device=str(self.device),
                dims=2048,
                num_workers=0  # ç¦ç”¨å¤šè¿›ç¨‹
            )
            
            return fid_score_val
            
        except Exception as e:
            print(f"FIDè®¡ç®—å¤±è´¥: {e}")
            raise e
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if processed_path1 != path1:
                shutil.rmtree(processed_path1, ignore_errors=True)
            if processed_path2 != path2:
                shutil.rmtree(processed_path2, ignore_errors=True)
                
    
    def _preprocess_images_to_uniform_size(self, input_path: str, target_size=(299, 299)) -> str:
        """
        é¢„å¤„ç†å›¾åƒåˆ°ç»Ÿä¸€å°ºå¯¸
        æ–°å¢æ–¹æ³• - æ·»åŠ åˆ°åŸæ¥çš„ç±»ä¸­
        """
        
        # å¦‚æœè¾“å…¥è·¯å¾„å·²ç»æ˜¯ä¸´æ—¶ç›®å½•ï¼Œç›´æ¥å¤„ç†
        if "tmp" in input_path or "temp" in input_path:
            self._resize_images_in_place(input_path, target_size)
            return input_path
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="fid_uniform_")
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_paths = self._get_image_paths(input_path)
        
        print(f"é¢„å¤„ç† {len(image_paths)} å¼ å›¾åƒåˆ°å°ºå¯¸ {target_size}")
        
        # å›¾åƒé¢„å¤„ç†å˜æ¢
        transform = transforms.Compose([
            transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.ToTensor(),
        ])
        
        # å¤åˆ¶å¹¶è°ƒæ•´æ‰€æœ‰å›¾åƒå°ºå¯¸
        copied_count = 0
        for img_path in image_paths:
            try:
                # åŠ è½½å’Œè°ƒæ•´å›¾åƒ
                with Image.open(img_path) as img:
                    # ç¡®ä¿æ˜¯RGBæ¨¡å¼
                    if img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    # è°ƒæ•´å°ºå¯¸
                    img_resized = img.resize(target_size, Image.Resampling.BILINEAR)
                    
                    # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                    filename = os.path.basename(img_path)
                    # ç¡®ä¿æ–‡ä»¶åæ˜¯å”¯ä¸€çš„
                    base_name, ext = os.path.splitext(filename)
                    if not ext.lower() in ['.jpg', '.jpeg', '.png']:
                        ext = '.jpg'
                    
                    new_filename = f"{copied_count:06d}_{base_name}{ext}"
                    dst_path = os.path.join(temp_dir, new_filename)
                    
                    # ä¿å­˜ä¸ºJPEGæ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§
                    if ext.lower() in ['.jpg', '.jpeg']:
                        img_resized.save(dst_path, 'JPEG', quality=95)
                    else:
                        img_resized.save(dst_path, 'PNG')
                    
                    copied_count += 1
                    
            except Exception as e:
                print(f"é¢„å¤„ç†å›¾åƒå¤±è´¥ {os.path.basename(img_path)}: {e}")
                continue
        
        print(f"æˆåŠŸé¢„å¤„ç† {copied_count} å¼ å›¾åƒ")
        
        if copied_count == 0:
            raise ValueError(f"æ²¡æœ‰æˆåŠŸé¢„å¤„ç†ä»»ä½•å›¾åƒä» {input_path}")
        
        return temp_dir


    def _resize_images_in_place(self, directory: str, target_size=(299, 299)):
        """
        åœ¨ç›®å½•ä¸­ç›´æ¥è°ƒæ•´å›¾åƒå°ºå¯¸
        æ–°å¢æ–¹æ³• - æ·»åŠ åˆ°åŸæ¥çš„ç±»ä¸­
        """
        image_paths = self._get_image_paths(directory)
        
        for img_path in image_paths:
            try:
                with Image.open(img_path) as img:
                    if img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´å°ºå¯¸
                    if img.size != target_size:
                        img_resized = img.resize(target_size, Image.Resampling.BILINEAR)
                        
                        # ä¿å­˜å›åŸæ–‡ä»¶
                        if img_path.lower().endswith(('.jpg', '.jpeg')):
                            img_resized.save(img_path, 'JPEG', quality=95)
                        else:
                            img_resized.save(img_path, 'PNG')
                            
            except Exception as e:
                print(f"è°ƒæ•´å›¾åƒå°ºå¯¸å¤±è´¥ {os.path.basename(img_path)}: {e}")
                continue

    def _calculate_contributions_size_fixed(self, 
                                      image_paths_a: List[str],
                                      dataset_b_path: str,
                                      selected_indices: np.ndarray,
                                      baseline_fid: float,
                                      batch_size: int) -> np.ndarray:
        """
        ä¿®å¤ç‰ˆæœ¬çš„è´¡çŒ®è®¡ç®— - ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´
        ç›´æ¥æ›¿æ¢åŸä»£ç ä¸­çš„ _calculate_contributions_standard æ–¹æ³•
        """
        print("\nè®¡ç®—å•ä¸ªå›¾ç‰‡FIDè´¡çŒ® (å°ºå¯¸ä¿®å¤ç‰ˆ)...")
        
        contributions = np.zeros(len(image_paths_a))
        temp_base_dir = tempfile.mkdtemp(prefix="fid_size_fixed_")
        
        try:
            for idx in tqdm(selected_indices, desc="è®¡ç®—è´¡çŒ®"):
                subset_dir = os.path.join(temp_base_dir, f"subset_{idx}")
                os.makedirs(subset_dir, exist_ok=True)
                
                # å¤åˆ¶å…¶ä»–å›¾ç‰‡å¹¶è°ƒæ•´å°ºå¯¸
                copied_count = 0
                target_size = (299, 299)
                
                for i, img_path in enumerate(image_paths_a):
                    if i != idx:
                        try:
                            # ğŸ”‘ å…³é”®ä¿®å¤ï¼šå¤åˆ¶æ—¶å°±è°ƒæ•´å°ºå¯¸
                            with Image.open(img_path) as img:
                                if img.mode != 'RGB':
                                    img = img.convert('RGB')
                                
                                # è°ƒæ•´åˆ°ç»Ÿä¸€å°ºå¯¸
                                img_resized = img.resize(target_size, Image.Resampling.BILINEAR)
                                
                                # ä¿å­˜
                                dst_path = os.path.join(subset_dir, f"img_{i:06d}.jpg")
                                img_resized.save(dst_path, 'JPEG', quality=95)
                                copied_count += 1
                                
                        except Exception as e:
                            print(f"å¤„ç†å›¾åƒå¤±è´¥ {os.path.basename(img_path)}: {e}")
                            continue
                
                if copied_count < 2:
                    contributions[idx] = 0
                    shutil.rmtree(subset_dir, ignore_errors=True)
                    continue
                
                try:
                    # ğŸ”‘ ä½¿ç”¨ä¿®å¤ç‰ˆæœ¬çš„FIDè®¡ç®—
                    subset_fid = self._safe_calculate_fid_fixed(
                        subset_dir, dataset_b_path, min(batch_size, 8)
                    )
                    contributions[idx] = subset_fid - baseline_fid
                except Exception as e:
                    print(f"FIDè®¡ç®—å¤±è´¥ï¼Œç´¢å¼• {idx}: {e}")
                    contributions[idx] = 0
                
                shutil.rmtree(subset_dir, ignore_errors=True)
                
        finally:
            shutil.rmtree(temp_base_dir, ignore_errors=True)
        
        return contributions
    
    def calculate_image_fid_contributions(self, 
                                        dataset_a_path: str,
                                        dataset_b_path: str,
                                        batch_size: int = 50,
                                        sample_size: Optional[int] = None,
                                        use_efficient_method: bool = True) -> Dict:
        """
        è®¡ç®—æ•°æ®é›†Aä¸­æ¯å¼ å›¾ç‰‡å¯¹FIDçš„è´¡çŒ®
        è¿”å›æ ¼å¼ä¿®æ”¹ä¸ºåŒ…å« path_to_score å­—å…¸
        """
        
        print("=" * 60)
        print("å¼€å§‹è®¡ç®—FIDè´¡çŒ®åˆ†æ")
        print("=" * 60)
        
        # 1. è·å–æ•°æ®é›†Aä¸­çš„æ‰€æœ‰å›¾ç‰‡è·¯å¾„
        image_paths_a = self._get_image_paths(dataset_a_path)
        n_images = len(image_paths_a)
        
        print(f"æ•°æ®é›†AåŒ…å« {n_images} å¼ å›¾ç‰‡ï¼Œè·¯å¾„ä¸º{dataset_a_path}")
        print(f"æ•°æ®é›†Bè·¯å¾„: {dataset_b_path}")
        
        if n_images == 0:
            raise ValueError("æ•°æ®é›†Aä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
            
        selected_indices = np.arange(n_images)
        print(f"åˆ†ææ‰€æœ‰ {n_images} å¼ å›¾ç‰‡")
        
        # 3. è®¡ç®—åŸºå‡†FIDï¼ˆæ•°æ®é›†A vs æ•°æ®é›†Bï¼‰
        print("\nè®¡ç®—åŸºå‡†FID...")
        try:
            # baseline_fid = fid_score.calculate_fid_given_paths(
            #     [dataset_a_path, dataset_b_path],
            #     batch_size=batch_size,
            #     device=str(self.device),
            #     dims=2048,
            #     num_workers=0
            # )
            baseline_fid = self._safe_calculate_fid_fixed(
            dataset_a_path, dataset_b_path, min(batch_size, 16)
        )
            print(f"åŸºå‡†FIDåˆ†æ•°: {baseline_fid:.4f}")
        except Exception as e:
            print(f"è®¡ç®—åŸºå‡†FIDå¤±è´¥: {e}")
            return {'error': str(e)}
        
        # 4. è®¡ç®—æ¯å¼ å›¾ç‰‡çš„è´¡çŒ®
        # contributions = self._calculate_contributions_standard(
        #     image_paths_a, dataset_b_path, selected_indices, 
        #     baseline_fid, batch_size
        # )
        
        contributions = self._calculate_contributions_size_fixed(
            image_paths_a, dataset_b_path, selected_indices, 
            baseline_fid, min(batch_size, 16)
        )
        
        # 5. åˆ›å»ºè·¯å¾„åˆ°åˆ†æ•°çš„å­—å…¸
        path_to_score = {}
        for i, path in enumerate(image_paths_a):
            path_to_score[path] = float(contributions[i])
        
        # 6. åˆ†æç»“æœ
        analysis = self._analyze_contributions(contributions, image_paths_a, selected_indices)
        
        return {
            'baseline_fid': baseline_fid,
            'contributions': contributions,
            'path_to_score': path_to_score,  # æ–°å¢ï¼šè·¯å¾„åˆ°åˆ†æ•°çš„å­—å…¸
            'analysis': analysis,
            'image_paths': [image_paths_a[i] for i in selected_indices],
            'selected_indices': selected_indices.tolist(),
            'dataset_info': {
                'dataset_a': dataset_a_path,
                'dataset_b': dataset_b_path,
                'total_images': n_images,
                'analyzed_images': len(selected_indices)
            }
        }
    
    def _get_image_paths(self, dataset_path: str) -> List[str]:
        """è·å–æ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾ç‰‡è·¯å¾„"""
        extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')
        image_paths = []
        
        if os.path.isdir(dataset_path):
            for root, dirs, files in os.walk(dataset_path):
                for file in files:
                    if file.lower().endswith(extensions):
                        image_paths.append(os.path.join(root, file))
        else:
            raise ValueError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {dataset_path}")
            
        return sorted(image_paths)
    
    def _calculate_contributions_efficient(self, 
                                         image_paths_a: List[str],
                                         dataset_b_path: str,
                                         selected_indices: np.ndarray,
                                         baseline_fid: float,
                                         batch_size: int) -> np.ndarray:
        print("\nä½¿ç”¨é«˜æ•ˆæ–¹æ³•è®¡ç®—FIDè´¡çŒ®...")
        
        n_selected = len(selected_indices)
        contributions = np.zeros(len(image_paths_a))
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_base_dir = tempfile.mkdtemp(prefix="fid_analysis_")
        
        try:
            # æ‰¹é‡å¤„ç†ä»¥æé«˜æ•ˆç‡
            batch_size_analysis = min(5, n_selected)  # æ¯æ‰¹å¤„ç†çš„å›¾ç‰‡æ•°é‡
            
            for batch_start in tqdm(range(0, n_selected, batch_size_analysis), desc="æ‰¹é‡è®¡ç®—FIDè´¡çŒ®"):
                batch_end = min(batch_start + batch_size_analysis, n_selected)
                batch_indices = selected_indices[batch_start:batch_end]
                
                for idx in batch_indices:
                    # åˆ›å»ºä¸åŒ…å«å½“å‰å›¾ç‰‡çš„å­é›†
                    subset_dir = os.path.join(temp_base_dir, f"subset_{idx}")
                    os.makedirs(subset_dir, exist_ok=True)
                    
                    # å¤åˆ¶é™¤å½“å‰å›¾ç‰‡å¤–çš„æ‰€æœ‰å›¾ç‰‡ - ä¿®å¤è¿™é‡Œçš„é€»è¾‘é”™è¯¯
                    copied_count = 0
                    
                    for i, img_path in enumerate(image_paths_a):
                        if i != idx:  # ä¿®å¤ï¼šæ­£ç¡®æ’é™¤å½“å‰è¦åˆ†æçš„å›¾ç‰‡
                            try:
                                dst_path = os.path.join(subset_dir, f"img_{i}_{os.path.basename(img_path)}")
                                shutil.copy2(img_path, dst_path)
                                copied_count += 1
                            except Exception as e:
                                print(f"å¤åˆ¶å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
                    
                    if copied_count < 2:
                        print(f"è­¦å‘Š: ç´¢å¼• {idx} çš„å­é›†å›¾ç‰‡æ•°é‡ä¸è¶³ ({copied_count})")
                        contributions[idx] = 0
                        continue
                    
                    try:
                        # è®¡ç®—ç§»é™¤è¯¥å›¾ç‰‡åçš„FID
                        subset_fid = fid_score.calculate_fid_given_paths(
                            [subset_dir, dataset_b_path],
                            batch_size=max(min(batch_size, copied_count), 2),
                            device=str(self.device),
                            dims=2048,
                            num_workers=1
                        )
                        
                        # è®¡ç®—è´¡çŒ®: ç§»é™¤å›¾ç‰‡åFIDçš„å˜åŒ–
                        contributions[idx] = subset_fid - baseline_fid
                        
                    except Exception as e:
                        print(f"è®¡ç®—FIDå¤±è´¥ï¼Œç´¢å¼• {idx}: {e}")
                        contributions[idx] = 0
                    
                    # æ¸…ç†å½“å‰å­é›†ç›®å½•
                    shutil.rmtree(subset_dir, ignore_errors=True)
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(temp_base_dir, ignore_errors=True)
        
        # å¯¹æœªåˆ†æçš„å›¾ç‰‡ä½¿ç”¨æ’å€¼ä¼°è®¡
        analyzed_indices = set(selected_indices)
        if len(analyzed_indices) < len(image_paths_a):
            analyzed_contributions = contributions[selected_indices]
            mean_contribution = np.mean(analyzed_contributions)
            
            for i in range(len(image_paths_a)):
                if i not in analyzed_indices:
                    contributions[i] = mean_contribution
        
        return contributions
    
    def _calculate_contributions_standard(self, 
                                        image_paths_a: List[str],
                                        dataset_b_path: str,
                                        selected_indices: np.ndarray,
                                        baseline_fid: float,
                                        batch_size: int) -> np.ndarray:
        """æ ‡å‡†çš„è´¡çŒ®è®¡ç®—æ–¹æ³• - é€ä¸ªå¤„ç†"""
        print("\nä½¿ç”¨æ ‡å‡†æ–¹æ³•è®¡ç®—FIDè´¡çŒ®...")
        
        contributions = np.zeros(len(image_paths_a))
        temp_base_dir = tempfile.mkdtemp(prefix="fid_standard_")
        
        try:
            for idx in tqdm(selected_indices, desc="è®¡ç®—å•ä¸ªå›¾ç‰‡FIDè´¡çŒ®"):
                subset_dir = os.path.join(temp_base_dir, f"subset_{idx}")
                os.makedirs(subset_dir, exist_ok=True)
                
                # å¤åˆ¶å…¶ä»–å›¾ç‰‡
                copied_count = 0
                for i, img_path in enumerate(image_paths_a):
                    if i != idx:
                        try:
                            dst_path = os.path.join(subset_dir, f"img_{i}_{os.path.basename(img_path)}")
                            shutil.copy2(img_path, dst_path)
                            copied_count += 1
                        except Exception as e:
                            print(f"å¤åˆ¶å¤±è´¥ {img_path}: {e}")
                
                if copied_count < 2:
                    contributions[idx] = 0
                    shutil.rmtree(subset_dir, ignore_errors=True)
                    continue
                try:
                    subset_fid = fid_score.calculate_fid_given_paths(
                        [subset_dir, dataset_b_path],
                        batch_size=max(min(batch_size, copied_count), 2),
                        device=str(self.device),
                        dims=2048,
                        num_workers=1
                    )
                    contributions[idx] = subset_fid - baseline_fid
                except Exception as e:
                    print(f"FIDè®¡ç®—å¤±è´¥ï¼Œç´¢å¼• {idx}: {e}")
                    contributions[idx] = 0
                shutil.rmtree(subset_dir, ignore_errors=True)
        finally:
            shutil.rmtree(temp_base_dir, ignore_errors=True)
        
        return contributions
    
    def _analyze_contributions(self, 
                             contributions: np.ndarray, 
                             image_paths: List[str], 
                             selected_indices: np.ndarray) -> Dict:
        """åˆ†æè´¡çŒ®ç»“æœ"""
        
        analyzed_contributions = contributions[selected_indices]
        
        analysis = {
            'statistics': {
                'mean': float(np.mean(analyzed_contributions)),
                'std': float(np.std(analyzed_contributions)),
                'min': float(np.min(analyzed_contributions)),
                'max': float(np.max(analyzed_contributions)),
                'median': float(np.median(analyzed_contributions))
            },
            'quality_assessment': {
                'high_quality_count': int(np.sum(analyzed_contributions > 0)),
                'low_quality_count': int(np.sum(analyzed_contributions < 0)),
                'neutral_count': int(np.sum(analyzed_contributions == 0))
            }
        }
        
        # è¯†åˆ«æœ€å¥½å’Œæœ€å·®çš„å›¾ç‰‡
        sorted_indices = selected_indices[np.argsort(analyzed_contributions)]
        
        # æœ€å·®çš„å›¾ç‰‡ï¼ˆç§»é™¤åFIDæ˜¾è‘—æ”¹å–„ï¼‰
        worst_indices = sorted_indices[:min(10, len(sorted_indices))]
        analysis['worst_images'] = {
            'indices': worst_indices.tolist(),
            'paths': [image_paths[i] for i in worst_indices],
            'contributions': [float(contributions[i]) for i in worst_indices]
        }
        
        # æœ€å¥½çš„å›¾ç‰‡ï¼ˆç§»é™¤åFIDæ˜¾è‘—å˜å·®ï¼‰
        best_indices = sorted_indices[-min(10, len(sorted_indices)):][::-1]
        analysis['best_images'] = {
            'indices': best_indices.tolist(),
            'paths': [image_paths[i] for i in best_indices],
            'contributions': [float(contributions[i]) for i in best_indices]
        }
        
        return analysis

    def save_results(self, results: Dict, output_dir: str):
        """ä¿å­˜FIDè´¡çŒ®åˆ†æçš„è¯¦ç»†ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        with open(os.path.join(output_dir, 'fid_detailed_results.json'), 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜åˆ†ææ‘˜è¦
        analysis = results.get('analysis', {})
        summary_lines = [
            "FIDè´¡çŒ®åˆ†ææ‘˜è¦",
            "=" * 50,
            "",
            f"åŸºå‡†FIDåˆ†æ•°: {results.get('baseline_fid', 'N/A'):.4f}",
            "",
            "ç»Ÿè®¡ä¿¡æ¯:",
            f"  å¹³å‡è´¡çŒ®: {analysis.get('statistics', {}).get('mean', 0):.4f}",
            f"  æ ‡å‡†å·®: {analysis.get('statistics', {}).get('std', 0):.4f}",
            f"  æœ€å°å€¼: {analysis.get('statistics', {}).get('min', 0):.4f}",
            f"  æœ€å¤§å€¼: {analysis.get('statistics', {}).get('max', 0):.4f}",
            f"  ä¸­ä½æ•°: {analysis.get('statistics', {}).get('median', 0):.4f}",
            "",
            "è´¨é‡è¯„ä¼°:",
            f"  é«˜è´¨é‡å›¾ç‰‡æ•° (è´¡çŒ®>0): {analysis.get('quality_assessment', {}).get('high_quality_count', 0)}",
            f"  ä½è´¨é‡å›¾ç‰‡æ•° (è´¡çŒ®<0): {analysis.get('quality_assessment', {}).get('low_quality_count', 0)}",
            f"  ä¸­æ€§å›¾ç‰‡æ•° (è´¡çŒ®=0): {analysis.get('quality_assessment', {}).get('neutral_count', 0)}",
            "",
        ]
        
        # æ·»åŠ æœ€å·®å›¾ç‰‡ä¿¡æ¯
        worst_images = analysis.get('worst_images', {})
        if worst_images.get('paths'):
            summary_lines.extend([
                "æœ€å·®å›¾ç‰‡ (ç§»é™¤åFIDæ”¹å–„æœ€å¤š):",
                ""
            ])
            for i, (path, contrib) in enumerate(zip(worst_images['paths'], worst_images['contributions'])):
                summary_lines.append(f"  {i+1}. {os.path.basename(path)}: {contrib:.4f}")
            summary_lines.append("")
        
        # æ·»åŠ æœ€å¥½å›¾ç‰‡ä¿¡æ¯
        best_images = analysis.get('best_images', {})
        if best_images.get('paths'):
            summary_lines.extend([
                "æœ€å¥½å›¾ç‰‡ (ç§»é™¤åFIDå˜å·®æœ€å¤š):",
                ""
            ])
            for i, (path, contrib) in enumerate(zip(best_images['paths'], best_images['contributions'])):
                summary_lines.append(f"  {i+1}. {os.path.basename(path)}: {contrib:.4f}")
        
        with open(os.path.join(output_dir, 'fid_analysis_summary.txt'), 'w', encoding='utf-8') as f:
            f.write('\n'.join(summary_lines))
        
        print(f"FIDè¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}")


class ComprehensiveDiversityEvaluator:
    """ç»¼åˆå¤šæ ·æ€§è¯„ä¼°å™¨ - ç»Ÿä¸€å­—å…¸æ ¼å¼è¾“å‡º"""

    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = torch.device(device)
        self.results = {}
        self.path_to_score_results = {}  # æ–°å¢ï¼šç»Ÿä¸€çš„å­—å…¸æ ¼å¼ç»“æœ
        self.image_paths = []
        
        # åˆå§‹åŒ–æ”¹è¿›çš„FIDè®¡ç®—å™¨
        self.fid_calculator = ImprovedFIDContributionCalculator(device)

        # åˆå§‹åŒ–å„ä¸ªè¯„ä¼°å™¨
        self._init_evaluators()

    def _init_evaluators(self):
        self.inception_model = inception_v3(pretrained=True, transform_input=False)
        self.inception_model.eval()
        self.inception_model = self.inception_model.to(self.device)

        self.inception_transform = transforms.Compose([
            transforms.Resize((299, 299)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        # Initialize LPIPS
        try:
            self.lpips_model = lpips.LPIPS(net='alex').to(self.device)
            self.lpips_transform = transforms.Compose([
                transforms.Resize((256, 256)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                     std=[0.5, 0.5, 0.5])
            ])
        except Exception as e:
            print(f"Warning: LPIPS not available: {e}")
            self.lpips_model = None

        # Initialize CLIP and Inception metrics if available
        if CLIP_AVAILABLE:
            try:
                self.clip_metrics = ClipMetrics()
                self.inception_metrics = InceptionMetrics()
            except Exception as e:
                print(f"Warning: Could not initialize CLIP/Inception metrics: {e}")
                self.clip_metrics = None
                self.inception_metrics = None
        else:
            self.clip_metrics = None
            self.inception_metrics = None

    def load_dataset(self, dataset_path: str,
                     extensions: Tuple[str] = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
        """åŠ è½½æ•°æ®é›†"""
        self.image_path = dataset_path
        self.image_paths = []

        if os.path.isdir(dataset_path):
            for root, dirs, files in os.walk(dataset_path):
                for file in files:
                    if file.lower().endswith(extensions):
                        self.image_paths.append(os.path.join(root, file))
        else:
            raise ValueError("æ•°æ®é›†è·¯å¾„å¿…é¡»æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹")

        print(f"å‘ç° {len(self.image_paths)} å¼ å›¾ç‰‡")
        return len(self.image_paths)

    def _create_path_to_score_dict(self, scores: np.ndarray, valid_paths: List[str] = None) -> Dict[str, float]:
        """åˆ›å»ºè·¯å¾„åˆ°åˆ†æ•°çš„å­—å…¸"""
        if valid_paths is None:
            valid_paths = self.image_paths
        
        if len(scores) != len(valid_paths):
            # å¦‚æœåˆ†æ•°æ•°é‡ä¸è·¯å¾„ä¸åŒ¹é…ï¼Œå°è¯•å¯¹é½
            min_len = min(len(scores), len(valid_paths))
            scores = scores[:min_len]
            valid_paths = valid_paths[:min_len]
        
        return {path: float(score) for path, score in zip(valid_paths, scores)}

    def compute_fid_contributions_improved(self, 
                                         reference_dataset_path: str,
                                         batch_size: int = 50,
                                         sample_size: Optional[int] = None) -> Dict[str, float]:
        """ä½¿ç”¨æ”¹è¿›çš„FIDè´¡çŒ®è®¡ç®—æ–¹æ³•ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        
        # ä½¿ç”¨å½“å‰æ•°æ®é›†è·¯å¾„
        current_dataset_path = self.image_path
        if not current_dataset_path:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®é›†")
        
        # è°ƒç”¨æ”¹è¿›çš„FIDè®¡ç®—å™¨
        results = self.fid_calculator.calculate_image_fid_contributions(
            dataset_a_path=current_dataset_path,
            dataset_b_path=reference_dataset_path,
            batch_size=batch_size,
            sample_size=sample_size,
            use_efficient_method=True
        )
        
        if 'error' in results:
            raise RuntimeError(f"FIDè®¡ç®—å¤±è´¥: {results['error']}")
        
        # å­˜å‚¨è¯¦ç»†ç»“æœç”¨äºåç»­åˆ†æ
        self.fid_detailed_results = results
        
        return results['path_to_score']

    def compute_is_contributions(self, batch_size: int = 32) -> Dict[str, float]:
        """è®¡ç®—æ¯å¼ å›¾ç‰‡å¯¹ISçš„è´¡çŒ®ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        print("è®¡ç®—ISè´¡çŒ®...")

        # æå–æ‰€æœ‰å›¾ç‰‡çš„é¢„æµ‹åˆ†å¸ƒ
        dataset = ImageDataset(self.image_paths, self.inception_transform)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)

        predictions = []
        valid_paths = []

        self.inception_model.eval()
        with torch.no_grad():
            for batch_images, batch_paths in tqdm(dataloader, desc="æå–Inceptionç‰¹å¾"):
                # Skip None leftImg8bit
                valid_batch = []
                valid_batch_paths = []
                
                for img, path in zip(batch_images, batch_paths):
                    if img is not None:
                        valid_batch.append(img)
                        valid_batch_paths.append(path)
                
                if not valid_batch:
                    continue
                    
                batch_tensor = torch.stack(valid_batch).to(self.device)
                outputs = self.inception_model(batch_tensor)
                probs = F.softmax(outputs, dim=1)

                predictions.append(probs.cpu().numpy())
                valid_paths.extend(valid_batch_paths)

        if not predictions:
            return {}
            
        predictions = np.concatenate(predictions, axis=0)

        # ä½¿ç”¨ç®€åŒ–çš„Shapleyå€¼è¿‘ä¼¼æ–¹æ³•
        shapley_values = self._compute_shapley_values_fast(predictions)

        return self._create_path_to_score_dict(shapley_values, valid_paths)

    def _compute_shapley_values_fast(self, predictions: np.ndarray, sample_size: int = 100) -> np.ndarray:
        """å¿«é€Ÿè¿‘ä¼¼è®¡ç®—Shapleyå€¼ - å‡å°‘é‡‡æ ·ä»¥æé«˜é€Ÿåº¦"""
        n = len(predictions)
        shapley_values = np.zeros(n)

        # Reduce sample size for faster computation
        # effective_sample_size = min(sample_size, max(10, n // 10))
        effective_sample_size = n

        for i in tqdm(range(n), desc=f"è®¡ç®—Shapleyå€¼ï¼Œä¸ªæ•°ä¸º{len(predictions)}"):
            marginal_contributions = []
            other_indices = [j for j in range(n) if j != i]

            for _ in range(effective_sample_size):
                # éšæœºé€‰æ‹©å­é›†å¤§å°
                max_subset_size = min(len(other_indices), 20)  # Limit subset size
                subset_size = np.random.randint(0, max_subset_size + 1)

                if subset_size == 0:
                    subset = []
                else:
                    subset = np.random.choice(other_indices,
                                              size=subset_size,
                                              replace=False).tolist()

                # è®¡ç®—è¾¹é™…è´¡çŒ®
                is_without = self._compute_is_score(predictions[subset]) if subset else 1.0
                subset_with_i = subset + [i]
                is_with = self._compute_is_score(predictions[subset_with_i])

                marginal_contribution = is_with - is_without
                marginal_contributions.append(marginal_contribution)

            shapley_values[i] = np.mean(marginal_contributions)

        return shapley_values

    def _compute_is_score(self, predictions: np.ndarray) -> float:
        """è®¡ç®—ISåˆ†æ•°"""
        if len(predictions) == 0:
            return 1.0

        # è®¡ç®—è¾¹é™…åˆ†å¸ƒ
        marginal_dist = np.mean(predictions, axis=0)

        # è®¡ç®—KLæ•£åº¦
        kl_divergences = []
        for pred in predictions:
            kl_div = np.sum(pred * (np.log(pred + 1e-10) -
                                    np.log(marginal_dist + 1e-10)))
            kl_divergences.append(kl_div)

        return np.exp(np.mean(kl_divergences))

    def compute_lpips_diversity_scores(self, batch_size: int = 50, 
                                     sample_size: Optional[int] = None) -> Dict[str, float]:
        """è®¡ç®—LPIPSå¤šæ ·æ€§åˆ†æ•°ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        if self.lpips_model is None:
            raise RuntimeError("LPIPS not available. Please install lpips.")

        print("è®¡ç®—LPIPSå¤šæ ·æ€§åˆ†æ•°...")
        n_images = len(self.image_paths)
        
        # If dataset is large, use sampling
        if sample_size and sample_size < n_images:
            indices = np.random.choice(n_images, sample_size, replace=False)
            sampled_paths = [self.image_paths[i] for i in indices]
            n_images = sample_size
            image_paths = sampled_paths
        else:
            image_paths = self.image_paths
            
        # é¢„åŠ è½½æ‰€æœ‰å›¾ç‰‡
        images = []
        valid_paths = []
        for img_path in tqdm(image_paths, desc="åŠ è½½å›¾ç‰‡"):
            try:
                img = Image.open(img_path).convert('RGB')
                img_tensor = self.lpips_transform(img).unsqueeze(0).to(self.device)
                images.append(img_tensor)
                valid_paths.append(img_path)
            except Exception as e:
                print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {img_path}: {e}")

        # è®¡ç®—æ¯å¼ å›¾ç‰‡çš„å¤šæ ·æ€§åˆ†æ•°
        diversity_scores = []
        for i in tqdm(range(len(images)), desc="è®¡ç®—LPIPSå¤šæ ·æ€§"):
            distances = []
            for j in range(len(images)):
                if i != j:
                    try:
                        with torch.no_grad():
                            lpips_dist = self.lpips_model(images[i], images[j]).item()
                        distances.append(lpips_dist)
                    except Exception as e:
                        print(f"è®¡ç®—LPIPSå¤±è´¥ {i}-{j}: {e}")
            
            diversity_scores.append(np.mean(distances) if distances else 0.0)

        return self._create_path_to_score_dict(np.array(diversity_scores), valid_paths)
    def compute_ssim_diversity_scores(self, batch_size: int = 50, 
                                sample_size: Optional[int] = None) -> Dict[str, float]:
        """è®¡ç®—SSIMå¤šæ ·æ€§åˆ†æ•°ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        print("è®¡ç®—SSIMå¤šæ ·æ€§åˆ†æ•°...")
        n_images = len(self.image_paths)
        
        image_paths = self.image_paths
            
        # é¢„åŠ è½½æ‰€æœ‰å›¾ç‰‡ï¼ˆè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼‰
        images = []
        valid_paths = []
        
        # SSIMä¸“ç”¨çš„transformï¼ˆä¸éœ€è¦å½’ä¸€åŒ–ï¼‰
        ssim_transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor()
        ])
        
        for img_path in tqdm(image_paths, desc="åŠ è½½å›¾ç‰‡"):
            try:
                img = Image.open(img_path).convert('RGB')
                img_tensor = ssim_transform(img)
                # è½¬æ¢ä¸ºnumpyæ ¼å¼ (H, W, C)ï¼ŒèŒƒå›´[0,1]
                img_np = img_tensor.permute(1, 2, 0).numpy()
                img_np = np.clip(img_np, 0, 1)
                images.append(img_np)
                valid_paths.append(img_path)
            except Exception as e:
                print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {img_path}: {e}")

        # è®¡ç®—æ¯å¼ å›¾ç‰‡çš„SSIMå¤šæ ·æ€§åˆ†æ•°
        diversity_scores = []
        for i in tqdm(range(len(images)), desc="è®¡ç®—SSIMå¤šæ ·æ€§"):
            ssim_values = []
            for j in range(len(images)):
                if i != j:
                    try:
                        # è®¡ç®—RGBå›¾åƒçš„SSIM
                        ssim_val = ssim(images[i], images[j], data_range=1.0, 
                                    channel_axis=2, multichannel=True)
                        ssim_values.append(ssim_val)
                    except Exception as e:
                        print(f"è®¡ç®—SSIMå¤±è´¥ {i}-{j}: {e}")
            
            # è®¡ç®—å¹³å‡SSIMï¼Œç„¶åè½¬æ¢ä¸ºè·ç¦»åº¦é‡ï¼ˆ1-SSIMï¼‰ä»¥ä¿æŒä¸å…¶ä»–æŒ‡æ ‡çš„ä¸€è‡´æ€§
            if ssim_values:
                avg_ssim = np.mean(ssim_values)
                diversity_score = 1.0 - avg_ssim  # è½¬æ¢ä¸ºè·ç¦»åº¦é‡ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºè¶Šä¸ç›¸ä¼¼ï¼ˆè¶Šå¤šæ ·ï¼‰
            else:
                diversity_score = 0.0
                
            diversity_scores.append(diversity_score)

        return self._create_path_to_score_dict(np.array(diversity_scores), valid_paths)


    def compute_tce_contributions(self, batch_size: int = 30) -> Dict[str, float]:
        """è®¡ç®—TCEè´¡çŒ®ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        if self.clip_metrics is None:
            print("TCE not available - CLIP metrics not initialized")
            return {}

        print("è®¡ç®—TCEè´¡çŒ®...")
        try:
            dataset_dir = self.image_path
            contributions, full_tce = self.clip_metrics.calculate_individual_tce_contributions(
                dataset_dir, batch_size=batch_size
            )

            return contributions
        except Exception as e:
            print(f"TCEè®¡ç®—å¤±è´¥: {e}")
            return {}

    def compute_tie_contributions(self, batch_size: int = 30) -> Dict[str, float]:
        """è®¡ç®—TIEè´¡çŒ®ï¼Œè¿”å›å­—å…¸æ ¼å¼"""
        if self.inception_metrics is None:
            print("TIE not available - Inception metrics not initialized")
            return {}

        print("è®¡ç®—TIEè´¡çŒ®...")
        try:
            dataset_dir = self.image_path
            contributions, full_tie = self.inception_metrics.calculate_individual_tie_contributions(
                dataset_dir, batch_size=batch_size
            )

            return contributions
        except Exception as e:
            print(f"TIEè®¡ç®—å¤±è´¥: {e}")
            return {}

    def evaluate_all_metrics(self,
                             reference_dataset_path: Optional[str] = None,
                             compute_tce: bool = True,
                             compute_tie: bool = True,
                             compute_is: bool = True,
                             compute_fid: bool = True,
                             compute_lpips: bool = True,
                             compute_ssim: bool = True,
                             lpips_sample_size: Optional[int] = None,
                             ssim_sample_size: Optional[int] = None,
                             fid_sample_size: int = 500) -> Dict[str, Dict[str, float]]:
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼Œç»Ÿä¸€è¿”å›å­—å…¸æ ¼å¼"""
        
        print("\n" + "=" * 60)
        print("å¼€å§‹è®¡ç®—æ‰€æœ‰å¤šæ ·æ€§æŒ‡æ ‡")
        print("=" * 60)
        
        # # TCE
        # if compute_tce and self.clip_metrics is not None:
        #     try:
        #         tce_dict = self.compute_tce_contributions()
        #         if tce_dict:
        #             self.path_to_score_results['tce'] = tce_dict
        #             scores = list(tce_dict.values())
        #             print(f"TCEè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
        #         else:
        #             self.path_to_score_results['tce'] = {}
        #     except Exception as e:
        #         print(f"TCEè®¡ç®—å¤±è´¥: {e}")
        #         self.path_to_score_results['tce'] = {}

        # # TIE
        # if compute_tie and self.inception_metrics is not None:
        #     try:
        #         tie_dict = self.compute_tie_contributions()
        #         if tie_dict:
        #             self.path_to_score_results['tie'] = tie_dict
        #             scores = list(tie_dict.values())
        #             print(f"TIEè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
        #         else:
        #             self.path_to_score_results['tie'] = {}
        #     except Exception as e:
        #         print(f"TIEè®¡ç®—å¤±è´¥: {e}")
        #         self.path_to_score_results['tie'] = {}

        # # IS
        # if compute_is:
        #     try:
        #         is_dict = self.compute_is_contributions()
        #         if is_dict:
        #             self.path_to_score_results['is'] = is_dict
        #             scores = list(is_dict.values())
        #             print(f"ISè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
        #         else:
        #             self.path_to_score_results['is'] = {}
        #     except Exception as e:
        #         print(f"ISè®¡ç®—å¤±è´¥: {e}")
        #         self.path_to_score_results['is'] = {}

        # # FID
        # if compute_fid and reference_dataset_path:
        #     try:
        #         fid_dict = self.compute_fid_contributions_improved(
        #             reference_dataset_path, 
        #             sample_size=fid_sample_size,
        #         )
        #         if fid_dict:
        #             self.path_to_score_results['fid'] = fid_dict
        #             scores = list(fid_dict.values())
        #             print(f"FIDè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
        #         else:
        #             self.path_to_score_results['fid'] = {}
        #     except Exception as e:
        #         print(f"FIDè®¡ç®—å¤±è´¥: {e}")
        #         self.path_to_score_results['fid'] = {}

        # # LPIPS
        # if compute_lpips and self.lpips_model is not None:
        #     try:
        #         lpips_dict = self.compute_lpips_diversity_scores(sample_size=lpips_sample_size)
        #         if lpips_dict:
        #             self.path_to_score_results['lpips'] = lpips_dict
        #             scores = list(lpips_dict.values())
        #             print(f"LPIPSè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
        #         else:
        #             self.path_to_score_results['lpips'] = {}
        #     except Exception as e:
        #         print(f"LPIPSè®¡ç®—å¤±è´¥: {e}")
        #         self.path_to_score_results['lpips'] = {}

        # SSIM
        if compute_ssim:
            try:
                ssim_dict = self.compute_ssim_diversity_scores(sample_size=ssim_sample_size)
                if ssim_dict:
                    self.path_to_score_results['ssim'] = ssim_dict
                    scores = list(ssim_dict.values())
                    print(f"SSIMè®¡ç®—å®Œæˆ: mean={np.mean(scores):.4f}, std={np.std(scores):.4f}")
                else:
                    self.path_to_score_results['ssim'] = {}
            except Exception as e:
                print(f"SSIMè®¡ç®—å¤±è´¥: {e}")
                self.path_to_score_results['ssim'] = {}

        return self.path_to_score_results

    def select_diverse_images_by_score(self, metric: str, n_select: int = 100,
                                     most_diverse: bool = True) -> Tuple[List[str], List[float]]:
        """æ ¹æ®æŒ‡å®šæŒ‡æ ‡é€‰æ‹©æœ€å¤šæ ·æˆ–æœ€ä¸å¤šæ ·çš„å›¾ç‰‡ï¼Œè¿”å›è·¯å¾„å’Œåˆ†æ•°"""
        if metric not in self.path_to_score_results or not self.path_to_score_results[metric]:
            raise ValueError(f"æŒ‡æ ‡ {metric} çš„ç»“æœä¸å¯ç”¨")

        score_dict = self.path_to_score_results[metric]
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_items = sorted(score_dict.items(), key=lambda x: x[1], reverse=most_diverse)
        
        # é€‰æ‹©å‰n_selectä¸ª
        selected_items = sorted_items[:n_select]
        selected_paths = [item[0] for item in selected_items]
        selected_scores = [item[1] for item in selected_items]

        return selected_paths, selected_scores

    def save_path_to_score_results(self, output_dir: str):
        """ä¿å­˜æ‰€æœ‰æŒ‡æ ‡çš„{è·¯å¾„ï¼šåˆ†æ•°}å­—å…¸æ ¼å¼ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜æ¯ä¸ªæŒ‡æ ‡çš„å­—å…¸
        for metric_name, score_dict in self.path_to_score_results.items():
            if score_dict:
                output_file = os.path.join(output_dir, f'{metric_name}_path_to_score.json')
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(score_dict, f, indent=2, ensure_ascii=False)
                print(f"å·²ä¿å­˜ {metric_name} ç»“æœåˆ°: {output_file}")

        # ä¿å­˜æ‰€æœ‰æŒ‡æ ‡çš„æ±‡æ€»æ–‡ä»¶
        summary_file = os.path.join(output_dir, 'all_metrics_path_to_score.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(self.path_to_score_results, f, indent=2, ensure_ascii=False)
        print(f"å·²ä¿å­˜æ‰€æœ‰æŒ‡æ ‡æ±‡æ€»åˆ°: {summary_file}")

        # ä¿å­˜è¯¦ç»†çš„FIDåˆ†æç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(self, 'fid_detailed_results') and self.fid_detailed_results is not None:
            self.fid_calculator.save_results(
                self.fid_detailed_results, 
                os.path.join(output_dir, 'fid_detailed_analysis')
            )

        # ç”Ÿæˆé€‰æ‹©ç»“æœæŠ¥å‘Š
        self._generate_selection_report(output_dir)

    def _generate_selection_report(self, output_dir: str):
        """ç”Ÿæˆæ¯ä¸ªæŒ‡æ ‡çš„é€‰æ‹©ç»“æœæŠ¥å‘Š"""
        report_lines = [
            "å›¾åƒå¤šæ ·æ€§è¯„ä¼°é€‰æ‹©æŠ¥å‘Š",
            "=" * 50,
            ""
        ]

        for metric in self.path_to_score_results:
            if not self.path_to_score_results[metric]:
                continue
                
            try:
                # æœ€å¤šæ ·çš„10å¼ 
                most_diverse_paths, most_diverse_scores = self.select_diverse_images_by_score(
                    metric, n_select=10, most_diverse=True
                )
                
                # æœ€ä¸å¤šæ ·çš„10å¼ 
                least_diverse_paths, least_diverse_scores = self.select_diverse_images_by_score(
                    metric, n_select=10, most_diverse=False
                )

                report_lines.extend([
                    f"{metric.upper()} æŒ‡æ ‡åˆ†æ:",
                    f"  æ€»å›¾ç‰‡æ•°: {len(self.path_to_score_results[metric])}",
                    f"  åˆ†æ•°èŒƒå›´: {min(self.path_to_score_results[metric].values()):.4f} ~ {max(self.path_to_score_results[metric].values()):.4f}",
                    "",
                    f"  æœ€å¤šæ ·çš„10å¼ å›¾ç‰‡:",
                ])
                
                for i, (path, score) in enumerate(zip(most_diverse_paths, most_diverse_scores)):
                    report_lines.append(f"    {i+1}. {os.path.basename(path)}: {score:.4f}")
                
                report_lines.extend([
                    "",
                    f"  æœ€ä¸å¤šæ ·çš„10å¼ å›¾ç‰‡:",
                ])
                
                for i, (path, score) in enumerate(zip(least_diverse_paths, least_diverse_scores)):
                    report_lines.append(f"    {i+1}. {os.path.basename(path)}: {score:.4f}")
                
                report_lines.extend(["", ""])
                
            except Exception as e:
                report_lines.append(f"  {metric.upper()} åˆ†æå‡ºé”™: {e}")
                report_lines.append("")

        # ä¿å­˜æŠ¥å‘Š
        with open(os.path.join(output_dir, 'selection_report.txt'), 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

    def visualize_score_distributions(self, output_dir: str):
        """å¯è§†åŒ–æ‰€æœ‰æŒ‡æ ‡çš„åˆ†æ•°åˆ†å¸ƒ"""
        os.makedirs(output_dir, exist_ok=True)

        if not self.path_to_score_results:
            print("æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œå¯è§†åŒ–")
            return

        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„æŒ‡æ ‡
        valid_metrics = {k: v for k, v in self.path_to_score_results.items() if v}
        
        if not valid_metrics:
            print("æ²¡æœ‰æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®")
            return

        n_metrics = len(valid_metrics)
        fig, axes = plt.subplots(2, n_metrics, figsize=(5 * n_metrics, 10))

        if n_metrics == 1:
            axes = axes.reshape(-1, 1)

        for idx, (metric_name, score_dict) in enumerate(valid_metrics.items()):
            scores = list(score_dict.values())
            
            # ç›´æ–¹å›¾
            ax = axes[0, idx]
            ax.hist(scores, bins=50, alpha=0.7, edgecolor='black')
            ax.set_title(f'{metric_name.upper()} åˆ†æ•°åˆ†å¸ƒ')
            ax.set_xlabel('åˆ†æ•°')
            ax.set_ylabel('é¢‘æ¬¡')

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            mean_val = np.mean(scores)
            std_val = np.std(scores)
            ax.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.3f}')
            ax.axvline(mean_val + std_val, color='orange', linestyle='--', alpha=0.5)
            ax.axvline(mean_val - std_val, color='orange', linestyle='--', alpha=0.5)
            ax.legend()

            # ç®±çº¿å›¾
            ax = axes[1, idx]
            ax.boxplot(scores)
            ax.set_title(f'{metric_name.upper()} ç®±çº¿å›¾')
            ax.set_ylabel('åˆ†æ•°')

        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'score_distributions.png'), dpi=300, bbox_inches='tight')
        plt.close()

        print(f"åˆ†æ•°åˆ†å¸ƒå¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_dir}")


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # é…ç½®å‚æ•°
    # dataset_path = "/home/ictt/xhr/code/DNNTesting/reSSNT/data/ADEChallengeData2016/leftImg8bit/validation"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    dataset_path = "/home/ictt/xhr/code/DNNTesting/reSSNT/data/cityscapes/leftImg8bit/val"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    reference_dataset = dataset_path  # FIDè®¡ç®—é€šå¸¸ä½¿ç”¨åŒä¸€æ•°æ®é›†ä½œä¸ºå‚è€ƒ
    output_dir = "./diversity_results_dict_format"

    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ComprehensiveDiversityEvaluator()

    # åŠ è½½æ•°æ®é›†
    n_images = evaluator.load_dataset(dataset_path)
    print(f"åŠ è½½äº† {n_images} å¼ å›¾ç‰‡")

    # è¯„ä¼°æ‰€æœ‰æŒ‡æ ‡
    print("\n" + "=" * 60)
    print("å¼€å§‹è®¡ç®—æ‰€æœ‰å¤šæ ·æ€§æŒ‡æ ‡ (ç»Ÿä¸€å­—å…¸æ ¼å¼)")
    print("=" * 60)

    path_to_score_results = evaluator.evaluate_all_metrics(
        reference_dataset_path=reference_dataset,
        compute_tce=True,  # å¦‚æœæ²¡æœ‰image_diversityåº“åˆ™è®¾ä¸ºFalse
        compute_tie=True,  # å¦‚æœæ²¡æœ‰image_diversityåº“åˆ™è®¾ä¸ºFalse
        compute_is=True,
        compute_fid=True,
        compute_lpips=True,
        lpips_sample_size=n_images,  # é‡‡æ ·500å¼ å›¾ç‰‡è®¡ç®—LPIPS
        ssim_sample_size=n_images,   # æ–°å¢ï¼šSSIMé‡‡æ ·å¤§å°
        fid_sample_size=n_images,     # é‡‡æ ·500å¼ å›¾ç‰‡è®¡ç®—FIDè´¡çŒ®
    )

    # ä¿å­˜å­—å…¸æ ¼å¼ç»“æœ
    evaluator.save_path_to_score_results(output_dir)
    
    # å¯è§†åŒ–ç»“æœ
    evaluator.visualize_score_distributions(output_dir)

    # è¾“å‡ºæ‘˜è¦
    print("\n" + "=" * 60)
    print("è®¡ç®—å®Œæˆæ‘˜è¦")
    print("=" * 60)
    
    for metric_name, score_dict in path_to_score_results.items():
        if score_dict:
            scores = list(score_dict.values())
            print(f"{metric_name.upper()}: å›¾ç‰‡æ•°={len(scores)}, å‡å€¼={np.mean(scores):.4f}, æ ‡å‡†å·®={np.std(scores):.4f}")

    print(f"\nå®Œæˆï¼æ‰€æœ‰ç»“æœä»¥{{è·¯å¾„:åˆ†æ•°}}å­—å…¸æ ¼å¼ä¿å­˜åœ¨ {output_dir}")
    print("\nä¿å­˜çš„æ–‡ä»¶åŒ…æ‹¬:")
    print("- *_path_to_score.json: å„æŒ‡æ ‡çš„{è·¯å¾„:åˆ†æ•°}å­—å…¸")
    print("- all_metrics_path_to_score.json: æ‰€æœ‰æŒ‡æ ‡çš„æ±‡æ€»å­—å…¸")
    print("- selection_report.txt: å„æŒ‡æ ‡çš„æœ€ä½³/æœ€å·®å›¾ç‰‡é€‰æ‹©æŠ¥å‘Š")
    print("- score_distributions.png: åˆ†æ•°åˆ†å¸ƒå¯è§†åŒ–")


if __name__ == "__main__":
    main()